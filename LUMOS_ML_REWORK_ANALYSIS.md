# LUMOS ML Rework — Comprehensive Data Audit, Architecture Analysis & Implementation Plan

> **Issue B1 Resolution:** Expanding from GA-only NIBRS to full 51-state incident-level data  
> Based on ~58M incident records across 774 state-year directories, 48GB of NIBRS CSVs  
> February 21, 2026

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Data Audit — What You Now Have](#2-data-audit--what-you-now-have)
3. [Current ML Pipeline — Failure Analysis](#3-current-ml-pipeline--failure-analysis)
4. [Ground-Truth Label Strategy](#4-ground-truth-label-strategy)
5. [ML Architecture Options — Full Ideation](#5-ml-architecture-options--full-ideation)
6. [Recommended Architecture — Multi-Model Ensemble](#6-recommended-architecture--multi-model-ensemble)
7. [Model 1: Temporal Risk Predictor (LSTM/GRU)](#7-model-1-temporal-risk-predictor)
8. [Model 2: Spatial Crime Density Estimator (KDE + GNN)](#8-model-2-spatial-crime-density-estimator)
9. [Model 3: Contextual Safety Scorer (XGBoost/LightGBM)](#9-model-3-contextual-safety-scorer)
10. [Ensemble Integration & Scoring Pipeline](#10-ensemble-integration--scoring-pipeline)
11. [Feature Engineering from NIBRS](#11-feature-engineering-from-nibrs)
12. [Data Preprocessing Pipeline](#12-data-preprocessing-pipeline)
13. [NIBRS Data Integration — Expanding nibrs_data.py](#13-nibrs-data-integration--expanding-nibrs_datapy)
14. [Training Infrastructure](#14-training-infrastructure)
15. [Evaluation & Validation Strategy](#15-evaluation--validation-strategy)
16. [Migration Plan — Phased Implementation](#16-migration-plan--phased-implementation)
17. [Risk Assessment & Mitigations](#17-risk-assessment--mitigations)
18. [Appendix A: NIBRS Schema Reference](#appendix-a-nibrs-schema-reference)
19. [Appendix B: State Data Coverage Matrix](#appendix-b-state-data-coverage-matrix)
20. [Appendix C: Discarded Architecture Options](#appendix-c-discarded-architecture-options)

---

## 1. Executive Summary

### The Problem (Issue B1)
The previous ML pipeline suffered from two critical flaws:
1. **Georgia-only NIBRS:** Only 7 years of GA incident data was used for hourly temporal patterns, victim demographics, weapon rates, and agency-level crime rates. All other 50 states fell back to synthetic BJS-derived academic curves.
2. **Circular Training Labels:** The Keras neural network was trained on labels generated by the same formula it was blended with (85% formula + 15% ML), making it a no-op that added TensorFlow overhead for ~0 predictive value.

### What Changed
You now have **real NIBRS incident-level data for all 51 jurisdictions** (50 states + DC):
- **774 state-year directories** spanning 1991–2024
- **~58 million incident records** (NIBRS_incident.csv rows)
- **~48 GB** of relational CSV data
- **546 directories with actual data**, 225 empty shells
- **42 states** with 2024 data, additional states with data as recent as 2023

### What This Document Proposes
A complete ML rework using a **three-model ensemble** that eliminates circular training, leverages all 58M incidents for genuine ground-truth labels, and produces a safety score that meaningfully outperforms the formula:

| Model | Architecture | Input | Output | Role |
|-------|-------------|-------|--------|------|
| **M1: Temporal Risk** | Bi-LSTM / GRU | State, hour, day, month, offense mix | Hourly risk probability (0–1) | Replaces BJS synthetic curves with data-driven temporal patterns per state |
| **M2: Spatial Density** | KDE + optional GNN | Lat/lng, agency stats, region | Crime density score (0–1) | Estimates localized crime density from agency-level aggregates |
| **M3: Contextual Scorer** | XGBoost / LightGBM | 25+ engineered features | Safety score (0–100) | Final scorer using gradient-boosted trees trained on NIBRS-derived ground truth |

**Key Innovation:** Ground-truth labels are derived from **actual NIBRS crime rates per agency** (not from the scoring formula), breaking the circular dependency.

---

## 2. Data Audit — What You Now Have

### 2.1 State Coverage

**51 jurisdictions** with NIBRS data, spanning varying year ranges:

| Tier | States | Year Range | 2024 Data? | Incident Volume |
|------|--------|-----------|------------|-----------------|
| **Tier 1: Deep History** | AL, CO, CT, DC, DE, KS, KY, LA, MI, NE, NH, OH, OR, SC, SD, TN, TX, UT, VA, VT, WA, WI, WV | 10–24 years | Most yes | High |
| **Tier 2: Moderate History** | AR, AZ, GA, IA, ID, IL, ME, MO, MT, ND, OK, PA, RI | 7–19 years | Most yes | Moderate |
| **Tier 3: Recent Only** | AK, CA, FL, HI, IN, MD, MN, MS, NC, NJ, NM, NV, NY, WY | 3–8 years | Most yes | Varies |

### 2.2 Largest Datasets (2024)

| State | 2024 Incidents | Notes |
|-------|---------------|-------|
| TX | 1,464,024 | Largest single-year dataset |
| NY | 688,701 | |
| IL | 543,935 | |
| NC | 485,797 | |
| OH | 413,565 | |
| GA | 397,863 | Previously the only state used |
| MI | 393,366 | |
| TN | 381,164 | |
| WA | 359,614 | |
| CO | 295,942 | |

### 2.3 Missing 2024 Data (9 States)

AZ, CA, HI, MA, NE, NJ, OK, VA — these have data from 2023 or earlier.

### 2.4 NIBRS Relational Schema

Each state-year directory contains **~25 CSV files** forming a relational database:

```
NIBRS_incident.csv ──────────────────── Core: incident_id, agency_id, incident_hour, incident_date
    ├── NIBRS_OFFENSE.csv ────────────── offense_id, offense_code, location_id, attempt/complete
    │   ├── NIBRS_WEAPON.csv ─────────── weapon_id per offense
    │   └── NIBRS_CRIMINAL_ACT.csv ──── criminal act type per offense
    ├── NIBRS_VICTIM.csv ─────────────── victim demographics: age, sex, race, ethnicity
    │   ├── NIBRS_VICTIM_OFFENSE.csv ── links victims to offenses
    │   ├── NIBRS_VICTIM_INJURY.csv ── injury types per victim
    │   └── NIBRS_VICTIM_OFFENDER_REL.csv ── relationship (stranger/known)
    ├── NIBRS_OFFENDER.csv ───────────── offender demographics: age, sex, race
    ├── NIBRS_ARRESTEE.csv ───────────── arrest data: date, type, demographics
    ├── NIBRS_PROPERTY.csv ───────────── property loss/stolen/recovered
    │   └── NIBRS_PROPERTY_DESC.csv ── property descriptions
    └── NIBRS_SUSPECTED_DRUG.csv ─────── drug type/quantity
    
agencies.csv ─────────────────────────── Agency metadata: name, population, county, type,
                                          officer counts, NIBRS certification dates
NIBRS_month.csv ──────────────────────── Monthly reporting status per agency
NIBRS_OFFENSE_TYPE.csv ───────────────── Offense code → name, crime_against, category
NIBRS_LOCATION_TYPE.csv ──────────────── Location ID → name (46 location types)
NIBRS_WEAPON_TYPE.csv ────────────────── Weapon ID → name
REF_RACE.csv, NIBRS_ETHNICITY.csv ──── Demographics lookup tables
NIBRS_AGE.csv ────────────────────────── Age range lookup
```

### 2.5 Key Fields for ML

| CSV | Column | ML Use |
|-----|--------|--------|
| `NIBRS_incident` | `incident_hour` | Temporal modeling (hour of day) |
| `NIBRS_incident` | `incident_date` | Temporal modeling (day of week, month, season) |
| `NIBRS_incident` | `agency_id` | Spatial grouping (agency = city/jurisdiction) |
| `NIBRS_OFFENSE` | `offense_code` | Crime type classification, severity weighting |
| `NIBRS_OFFENSE` | `location_id` | Location-type risk (bar, residence, parking, etc.) |
| `NIBRS_VICTIM` | `sex_code`, `age_num` | Victim demographics for gender/age risk factors |
| `NIBRS_WEAPON` | `nibrs_weapon_id` | Weapon involvement rates |
| `NIBRS_VICTIM_OFFENDER_REL` | `relationship_id` | Stranger vs. known crime rates |
| `agencies` | `population` | Per-agency crime rate computation |
| `agencies` | `county_name`, `state_abbr` | Geographic grouping |
| `agencies` | `male_officer`, `female_officer` | Officer density (officers per capita) |
| `agencies` | `agency_type_name` | City vs. County vs. University vs. State patrol |
| `agencies` | `population_group_desc` | Urban/suburban/rural classification |

### 2.6 Schema Variations Across Years

| Era | Format | States Affected | Key Differences |
|-----|--------|----------------|-----------------|
| **Pre-2006** | Legacy lowercase, extra columns | AL-1991, CO-1992, etc. | Has `ddocname`, `ff_line_number`; no `data_year` |
| **2006–2019** | Mixed case, `OFFENSE_TYPE_ID` (numeric) | GA-2018, most 2006–2019 | Uses numeric offense type IDs, quoted UPPERCASE headers |
| **2020+** | Lowercase, `offense_code` (string) | All 2020+ datasets | Uses string offense codes (e.g., "13A"), lowercase headers |

The existing `nibrs_data.py` already handles the GA-2018 vs 2022+ format difference with `.upper()` normalization, but will need extension for pre-2006 legacy format.

---

## 3. Current ML Pipeline — Failure Analysis

### 3.1 The Circular Training Problem

```
┌──────────────────────────────────────────────────────────────┐
│                    CURRENT (BROKEN) PIPELINE                 │
│                                                              │
│  Real Data (crime_rate, population, ...)                     │
│       ↓                                                      │
│  Formula: base_safety = percentile_rank(crime_rate)          │
│       ↓                                                      │
│  Augmented Label: safety = base_safety ± adjustments         │
│       ↓                     ↑                                │
│  Train Keras NN on these labels ←──── CIRCULAR!              │
│       ↓                                                      │
│  Predict: ml_score = model.predict(features)                 │
│       ↓                                                      │
│  Blend: final = formula × 0.85 + ml_score × 0.15            │
│       ↓                                                      │
│  The ML model learned to mimic the formula it's blended with │
│  → Removing ML entirely changes output by < 5 points         │
└──────────────────────────────────────────────────────────────┘
```

### 3.2 Current Architecture Issues In Detail

| Issue | Impact | Evidence |
|-------|--------|---------|
| Labels are formula-derived | ML can't learn anything the formula doesn't know | `_compute_percentile_safety()` is the label generator |
| 85/15 blend makes ML irrelevant | At 15% weight, ML contributes 0–14 points max | `_FallbackModel(0.7)` achieves ~same result |
| Same features for both | ML sees exact same inputs as formula | 15 features shared between scoring.py and ml_model.py |
| No spatial features | Model has no concept of WHERE a location is | No lat/lng, no state encoding, no neighborhood ID |
| GA-only NIBRS for hourly patterns | 50/51 states get generic curves | `_load_ga_nibrs_hourly()` only reads GA directories |
| Synthetic augmentation dominates | Each of 12K records gets 6–24 augmented copies | 200K+ training vectors are synthetic noise around real values |
| County population guessed from crime | UCR Table 10 counties have no population | `est_pop = max(int(total / 0.03), 5000)` — unreliable |
| Single Dense NN architecture | Can't capture temporal sequences or spatial dependencies | 256→128→64→32→1 Dense layers only |

### 3.3 What the Current Model Actually Does

Running the current model:
1. Loads ~12K real records (CDE state-year + UCR city/college/county + hardcoded)
2. For each, computes `base_safety = percentile_rank(total_crime_rate)` — **this IS the label**
3. Adds ±8% noise from time, gender, weather, events — all formula-based
4. Trains a 5-layer Dense NN on 200K+ vectors to predict these formula-generated labels
5. At inference, blends 85% formula + 15% model prediction
6. The model has learned the formula's monotonic relationship between crime_rate and safety_score

**Effective contribution of current ML: ~0–5 points on a 100-point scale.**

---

## 4. Ground-Truth Label Strategy

This is **the most critical section**. Without proper labels, no architecture will help.

### 4.1 Why We Can't Use External Ground Truth

- No public dataset maps `(lat, lng, hour) → safety_score` with validated labels
- Crowd-sourced safety ratings (Numbeo, NeighborhoodScout) are subjective and sparse
- Victimization surveys (NCVS) are national, not per-location

### 4.2 NIBRS-Derived Ground Truth (The Answer)

With **58M real incidents across all 51 states**, we can compute **empirical crime density measures** that serve as ground truth. The key insight: **we don't need someone to label "safety = 72"** — we compute it from actual crime occurrence patterns.

#### Strategy: Agency-Level Crime Rates as Ground Truth

```
For each agency (≈ police department / jurisdiction):
  1. Count Part I Index Crime incidents from NIBRS
  2. Get agency population from agencies.csv
  3. Compute: annual_part1_rate = (part1_incidents / years) / population × 100,000
  4. Compute: safety_score = 1 - sigmoid(rate / reference_rate)
```

This gives us **real, per-jurisdiction crime rates** — not formula-generated fantasies.

#### Enhancement: Temporal Ground Truth

```
For each (agency, hour_of_day) pair:
  1. Count incidents at that hour across all available years
  2. Normalize by total agency incidents
  3. This gives P(incident | hour, agency) — a REAL temporal distribution
  
For each (agency, day_of_week) pair:
  1. Count incidents on that day across all available years  
  2. This gives P(incident | day, agency)

For each (agency, month) pair:
  1. Count incidents in that month
  2. This gives P(incident | month, agency) — seasonal patterns
```

#### Enhancement: Contextual Ground Truth

```
For each (agency, location_type) pair:
  1. Join NIBRS_OFFENSE.location_id → NIBRS_LOCATION_TYPE
  2. Compute: P(incident_at_location_type | agency)
  3. This tells us: "In Austin, 18% of crimes happen at residences, 12% at parking lots"

For each (agency, offense_code):
  1. Compute offense mix: P(offense_type | agency)
  2. Weight by severity
  3. This gives a violence-weighted danger metric

For each agency:
  1. Compute weapon involvement rate from NIBRS_WEAPON
  2. Compute stranger crime rate from NIBRS_VICTIM_OFFENDER_REL
  3. Compute victim gender distribution from NIBRS_VICTIM
```

### 4.3 Label Construction Pipeline

```python
def compute_ground_truth_label(agency_rate, hour, day_of_week, month, 
                                location_type, weapon_rate, stranger_rate,
                                victim_female_rate, officer_density):
    """
    Ground truth safety score from ACTUAL NIBRS data.
    
    No formula dependency — purely empirical.
    """
    # Base: empirical crime rate → safety percentile across all agencies
    base = 1.0 - percentile_among_all_agencies(agency_rate)  # 0-1
    
    # Temporal: actual hourly probability for THIS agency (not BJS curves)
    hourly_risk = agency_hourly_distribution[hour]  # from real NIBRS data
    temporal_modifier = hourly_risk / mean_hourly_risk  # relative risk at this hour
    
    # Day of week: real weekend vs weekday pattern for THIS agency
    dow_risk = agency_dow_distribution[day_of_week]
    dow_modifier = dow_risk / mean_dow_risk
    
    # Seasonal: real monthly pattern
    month_risk = agency_monthly_distribution[month]
    month_modifier = month_risk / mean_monthly_risk
    
    # Violence intensity: weapon rate × severity weighting
    violence_modifier = weapon_rate * stranger_rate * severity_weight
    
    # Final: multiplicative combination of empirical factors
    safety = base / (temporal_modifier * dow_modifier * month_modifier)
    safety *= (1 - violence_modifier * 0.1)
    safety *= (1 + officer_density * 0.05)  # more officers = slightly safer
    
    return clip(safety, 0.05, 0.95)
```

**Why this is NOT circular:** The labels come from counting real incidents, not from the scoring formula. The model learns patterns the formula cannot express (e.g., "Austin has higher crime on Thursday nights in June near bars" — something no formula captures).

---

## 5. ML Architecture Options — Full Ideation

### 5.1 Option A: Enhanced Dense Neural Network (Current + Fixed Labels)

**Idea:** Keep the Keras Dense NN but fix the training labels.

| Pros | Cons |
|------|------|
| Minimal code changes | Can't capture temporal sequences |
| Fast inference | No spatial awareness |
| Already integrated | Limited expressiveness for 58M incident patterns |
| Lightweight dependency | Still just learning a function mapping |

**Verdict:** ⚠️ Viable as a quick fix but wastes the massive NIBRS dataset potential.

### 5.2 Option B: XGBoost / LightGBM Gradient Boosted Trees

**Idea:** Replace Keras with gradient-boosted trees. Superior for tabular data.

| Pros | Cons |
|------|------|
| State-of-the-art for tabular data | No native temporal sequence modeling |
| Feature importance for interpretability | Still requires manual feature engineering |
| Fast training and inference | No spatial graph structure |
| No GPU required | Each prediction is independent (no context) |
| Handles missing values natively | |
| Smaller model size (~5MB vs ~50MB Keras) | |

**Verdict:** ✅ Strong candidate for the contextual scorer (M3).

### 5.3 Option C: LSTM / GRU Recurrent Neural Networks

**Idea:** Model crime as a temporal sequence — learn hourly, daily, and seasonal patterns.

| Pros | Cons |
|------|------|
| Naturally handles time series | Requires sequence padding/batching |
| Can learn long-range temporal dependencies | Computationally heavier than trees |
| State-specific temporal patterns | Overfitting risk on sparse agencies |
| Bidirectional variants capture future + past context | |

**Verdict:** ✅ Strong candidate for hourly risk prediction (M1).

### 5.4 Option D: Spatial-Temporal Graph Neural Network (ST-GNN)

**Idea:** Model the US as a graph where nodes = agencies/jurisdictions and edges = geographic adjacency. Each node has temporal features (hourly crime counts) and the graph learns spatial diffusion patterns.

**Architecture:**
```
Nodes: ~15,000 agencies across all states
Edges: Geographic adjacency (agencies in same county/neighboring counties)
Node features: Crime rate, offense mix, demographics, population
Temporal features: 24-hour × 7-day × 12-month crime patterns

Graph Convolution → Temporal Attention → Prediction
```

| Pros | Cons |
|------|------|
| Captures spatial crime diffusion | Complex to implement |
| Models geographic similarity | Requires PyTorch Geometric / DGL |
| Theoretically powerful | Heavy dependency (PyG) |
| Can learn "crime spreads from city A to adjacent city B" | Risk of overfitting without careful regularization |
| State-of-the-art in traffic/crime prediction literature | Overkill for a hackathon? |

**Verdict:** ⚠️ Theoretically ideal but implementation complexity is very high. The agency adjacency graph construction alone requires county-level geographic data that NIBRS doesn't provide (no lat/lng per agency). Would need to join with Census FIPS codes or geocode agency names.

### 5.5 Option E: Transformer-based Temporal Model

**Idea:** Use self-attention over temporal crime sequences.

| Pros | Cons |
|------|------|
| Powerful temporal modeling | Very heavy for inference |
| Attention weights are interpretable | Transformer overhead for 24-position sequence is extreme |
| Can handle variable-length sequences | Massive overkill for hourly patterns |

**Verdict:** ❌ Over-engineered. A 24-element hourly sequence doesn't justify transformer attention.

### 5.6 Option F: Kernel Density Estimation (KDE) — Non-ML

**Idea:** Skip ML for spatial density, use statistical KDE over agency crime rates within a state/region.

| Pros | Cons |
|------|------|
| No training required | No feature interaction modeling |
| Mathematically grounded | Can't incorporate contextual features |
| Fast computation | Limited to spatial density estimation |
| Perfect for "how does this agency compare to neighbors" | |

**Verdict:** ✅ Excellent complement to ML models for spatial density estimation.

### 5.7 Option G: Multi-Model Ensemble

**Idea:** Combine multiple specialized models, each handling a different aspect of safety prediction.

| Pros | Cons |
|------|------|
| Each model specializes in what it's best at | More code to maintain |
| Ensemble reduces individual model weaknesses | Slightly more complex inference |
| Interpretable: can show which component contributed what | |
| Incremental deployment: can add models one at a time | |
| Robust: if one model fails, others still contribute | |

**Verdict:** ✅✅ **RECOMMENDED.** Best balance of power, feasibility, and hackathon constraints.

---

## 6. Recommended Architecture — Multi-Model Ensemble

### 6.1 System Design

```
                          ┌─────────────────────────────────┐
                          │         User Request            │
                          │  (lat, lng, hour, gender, ...)  │
                          └──────────┬──────────────────────┘
                                     │
                    ┌────────────────┬┴───────────────┐
                    ↓                ↓                 ↓
         ┌──────────────┐  ┌──────────────┐  ┌──────────────────┐
         │   Model 1    │  │   Model 2    │  │    Model 3       │
         │  Temporal    │  │  Spatial     │  │  Contextual      │
         │  Risk (LSTM) │  │  Density     │  │  Scorer          │
         │              │  │  (KDE/Stats) │  │  (XGBoost)       │
         │              │  │              │  │                   │
         │ Input:       │  │ Input:       │  │ Input:            │
         │ state, hour, │  │ agency_id,   │  │ 25+ features     │
         │ day, month,  │  │ lat/lng,     │  │ (crime rate,     │
         │ offense_mix  │  │ population   │  │  temporal risk,   │
         │              │  │ group        │  │  spatial density, │
         │ Output:      │  │              │  │  weather, gender, │
         │ hourly_risk  │  │ Output:      │  │  events, etc.)   │
         │ (0-1)        │  │ density_score│  │                   │
         │              │  │ (0-1)        │  │ Output:           │
         └──────┬───────┘  └──────┬───────┘  │ safety_score     │
                │                 │           │ (0-100)          │
                │                 │           └────────┬─────────┘
                │                 │                    │
                └────────┬────────┘                    │
                         │                             │
              ┌──────────┴──────────┐                  │
              │  Feature inputs to  │──────────────────┘
              │  Model 3 (M1 & M2  │
              │  outputs become     │
              │  features for M3)   │
              └─────────────────────┘
                                     │
                          ┌──────────┴──────────────────┐
                          │    Gemini Refinement (±15)   │
                          │    (unchanged from current)  │
                          └──────────┬──────────────────┘
                                     │
                          ┌──────────┴──────────────────┐
                          │      Final Safety Score     │
                          │         (5–95)              │
                          └─────────────────────────────┘
```

### 6.2 Why This Architecture

1. **M1 (Temporal)** replaces BJS synthetic curves with **real per-state hourly/daily/seasonal patterns** learned from NIBRS. Now every state has data-driven temporal risk.

2. **M2 (Spatial)** provides a **statistically grounded crime density estimate** for each agency/jurisdiction, replacing the crude "state rate × urban/suburban/rural multiplier" heuristic.

3. **M3 (Contextual)** takes M1 and M2 outputs as features alongside weather, gender, events, POIs, etc. — producing the final score. Trained on NIBRS-derived ground truth labels (not formula-generated), breaking the circular dependency.

4. **Gemini refinement** stays as-is — it provides subjective contextual adjustment that no model can replicate (e.g., "this neighborhood gentrified recently").

### 6.3 Benefits Over Current System

| Metric | Current | Proposed |
|--------|---------|----------|
| Training data | ~12K records → 200K synthetic | ~58M real incidents → 15K+ agency profiles |
| Ground truth | Formula-generated (circular) | NIBRS-computed empirical rates |
| Temporal patterns | GA-only real, 50 states synthetic | All 51 states real from NIBRS |
| Spatial resolution | State-level (state × multiplier) | Agency-level (city/county) |
| Architecture | Single Dense NN (tabular) | Ensemble (temporal + spatial + contextual) |
| Interpretability | Black-box blend | Each model's contribution is explainable |
| Inference weight | 15% blend (essentially ignored) | 70%+ ML-driven (formula becomes baseline only) |
| TensorFlow dependency | Required (~500MB) | Can use lighter frameworks (sklearn, xgboost, PyTorch) |

---

## 7. Model 1: Temporal Risk Predictor

### 7.1 Purpose
Learn per-state hourly crime patterns directly from NIBRS incident timestamps. Replace the BJS-derived synthetic curves for all 50 non-GA states.

### 7.2 Architecture Options

#### Option A: Pre-computed Lookup Tables (Simplest, Recommended for Hackathon)

Instead of a neural network, precompute empirical hourly distributions from NIBRS data for every state:

```python
# For each state, for each hour 0-23:
#   P(incident | hour, state) = count(incidents at hour h in state s) / total(incidents in state s)
#
# Also compute per-offense-type hourly distributions for severity weighting.

state_hourly_profiles = {}  # state_abbr → np.ndarray(24,)
state_hourly_by_offense = {}  # state_abbr → {offense_code: np.ndarray(24,)}
state_dow_profiles = {}  # state_abbr → np.ndarray(7,)
state_monthly_profiles = {}  # state_abbr → np.ndarray(12,)
```

**Advantages:**
- Zero inference latency (dictionary lookup)
- 100% interpretable
- Trivial to implement
- No new ML dependencies
- Can be computed once and cached to JSON

**When to upgrade to LSTM:** Only if you need to predict FUTURE temporal trends (e.g., "crime is increasing in Atlanta in Q3 2024"), which the current product doesn't require.

#### Option B: Bi-LSTM for Temporal Sequences (If You Want a Neural Approach)

```python
import torch
import torch.nn as nn

class TemporalRiskPredictor(nn.Module):
    """
    Predicts hourly risk given state context.
    
    Input: (batch, seq_len=24, features=state_embed_dim + offense_mix_dim)
    Output: (batch, 24) — risk probability per hour
    """
    def __init__(self, state_count=51, offense_dim=8, hidden=64):
        super().__init__()
        self.state_embed = nn.Embedding(state_count, 16)
        self.lstm = nn.LSTM(
            input_size=16 + offense_dim + 4,  # state_embed + offense_mix + cyclical time
            hidden_size=hidden,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=0.2,
        )
        self.fc = nn.Sequential(
            nn.Linear(hidden * 2, 32),  # bidirectional doubles hidden
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid(),
        )
    
    def forward(self, state_id, offense_mix, time_features):
        # state_id: (batch,) → (batch, 24, 16) repeated
        state_emb = self.state_embed(state_id).unsqueeze(1).expand(-1, 24, -1)
        # offense_mix: (batch, 8) → (batch, 24, 8) repeated
        off_emb = offense_mix.unsqueeze(1).expand(-1, 24, -1)
        # time_features: (batch, 24, 4) — sin/cos of hour, day_of_week features
        x = torch.cat([state_emb, off_emb, time_features], dim=-1)
        lstm_out, _ = self.lstm(x)
        risk = self.fc(lstm_out).squeeze(-1)  # (batch, 24)
        return risk
```

### 7.3 Training Data

```
For each state with NIBRS data:
  For each year directory:
    Load NIBRS_incident.csv
    Extract: incident_hour, incident_date
    Group by hour → hourly_counts[0..23]
    Group by day_of_week → dow_counts[0..6]  
    Group by month → monthly_counts[0..11]
    
    Join with NIBRS_OFFENSE.csv on incident_id:
      Get offense_code per incident
      Compute offense mix: P(offense_code | state, year)
    
    Join with NIBRS_WEAPON.csv on offense_id:
      Compute hourly weapon involvement rates

→ Result: 774 state-year temporal profiles with real data
```

### 7.4 Recommended Approach

**Use Pre-computed Lookup Tables (Option A).** Rationale:
- The temporal patterns are empirical distributions, not predictions
- 51 states × 24 hours = 1,224 values — fits in a JSON file
- No model training needed — just data aggregation
- Can add day-of-week and monthly granularity trivially
- More robust than LSTM for this data volume per state

---

## 8. Model 2: Spatial Crime Density Estimator

### 8.1 Purpose
Estimate localized crime density for a given lat/lng, replacing the crude "state rate × urban/suburban/rural multiplier" heuristic in `estimate_local_crime_rate()`.

### 8.2 Architecture: Agency-Level Statistical Model

The NIBRS `agencies.csv` provides **population per agency** and we can compute **Part I crime rates per agency** from incident counts. This gives us ~15,000 agency-level data points with real crime rates.

```python
class SpatialDensityEstimator:
    """
    Agency-level crime density estimation using statistical methods.
    
    Approach:
    1. Pre-compute Part I crime rate for every NIBRS agency
    2. Group by population_group (FBI urban/suburban/rural classification)
    3. At inference: match user location to nearest agency(ies)
       via city name fuzzy match + state + population group
    4. Return interpolated crime density score
    """
    
    def __init__(self):
        self.agency_rates = {}  # agency_name → rate_per_100k
        self.state_agency_rates = {}  # state_abbr → [list of agency rates]
        self.population_group_medians = {}  # pop_group → median rate
        self.state_medians = {}  # state_abbr → median rate
        
    def estimate(self, city_name, state_abbr, population, lat, lng):
        """
        Multi-tier estimation:
        1. Exact agency match → use its real Part I rate
        2. Same county match → use county median of agency rates
        3. Same population group in state → use group median
        4. State median → fallback
        """
        # Tier 1: Exact match
        rate = self._exact_match(city_name, state_abbr)
        if rate: return rate
        
        # Tier 2: County interpolation
        rate = self._county_interpolation(city_name, state_abbr)
        if rate: return rate
        
        # Tier 3: Population group within state
        pop_group = self._classify_population_group(population)
        rate = self._pop_group_match(state_abbr, pop_group)
        if rate: return rate
        
        # Tier 4: State median
        return self.state_medians.get(state_abbr, 2800)  # national avg fallback
```

### 8.3 Optional: Graph Neural Network Enhancement

If agency adjacency is available (via county co-occurrence):

```
Nodes: agencies (15K+)
Edges: agencies in same county are connected
Node features: [crime_rate, population, officer_rate, offense_mix(8), pop_group]
Edge features: [same_county, population_ratio]

GCN layers learn: "agencies in the same county have correlated crime rates"
→ Smooths estimates for agencies with sparse data by borrowing
  information from geographic neighbors
```

**Verdict for GNN:** Save for post-hackathon. The statistical approach above is already a massive improvement over the current state × multiplier heuristic.

### 8.4 Recommended Approach

**Agency-Level Statistical Model with KDE smoothing.** 
- Pre-compute Part I rates for all 15K agencies
- Group by state + population group for interpolation
- Use fuzzy matching for city name → agency mapping
- Fall back gracefully to state/population-group medians

---

## 9. Model 3: Contextual Safety Scorer (XGBoost/LightGBM)

### 9.1 Purpose
Final safety score predictor that takes ALL available features (including M1 and M2 outputs) and produces the 0–100 safety score. Trained on **NIBRS-derived ground truth labels**.

### 9.2 Why XGBoost/LightGBM Over Neural Networks

Research consistently shows gradient-boosted trees outperform neural networks on tabular data with <100K samples and <100 features:

| Factor | XGBoost | Dense NN |
|--------|---------|----------|
| Tabular data performance | State-of-the-art | Worse on structured data |
| Interpretability | SHAP values, feature importance | Black box |
| Training speed | Minutes | Hours |
| Missing value handling | Native | Manual imputation needed |
| Overfitting resistance | Built-in regularization | Requires dropout + early stopping |
| Model size | ~5MB | ~50MB (with TF runtime) |
| Inference speed | ~0.1ms | ~5ms |
| Dependencies | `xgboost` (7MB) | `tensorflow` (500MB+) |

### 9.3 Feature Vector (25 Features)

```python
FEATURE_NAMES_V2 = [
    # ── Crime Features (from M2 / NIBRS-derived) ──
    "agency_part1_rate",          # Real Part I crime rate for matched agency
    "agency_violent_rate",        # Violent crime rate specifically
    "agency_property_rate",       # Property crime rate specifically
    "agency_weapon_rate",         # Fraction of offenses involving weapons
    "agency_stranger_rate",       # Fraction of crimes by strangers
    "agency_severity_score",      # Severity-weighted average offense score
    "state_crime_rate_norm",      # Normalized state-level crime rate
    "population_group",           # FBI pop group encoding (0-11)
    
    # ── Temporal Features (from M1 / NIBRS-derived) ──
    "hourly_risk_ratio",          # P(crime at hour h | agency) / mean hourly P
    "dow_risk_ratio",             # P(crime on day d | agency) / mean daily P
    "monthly_risk_ratio",         # P(crime in month m | agency) / mean monthly P
    "time_sin",                   # sin(2π × hour / 24) — cyclical encoding
    "time_cos",                   # cos(2π × hour / 24)
    "is_weekend",                 # Boolean
    
    # ── Contextual Features ──
    "people_count_norm",          # Group size (1-4) / 4
    "gender_factor",              # From NIBRS victim demographics
    "weather_severity",           # NWS/OWM severity (0-1)
    "officer_density",            # Officers per 1,000 population
    "is_college",                 # Boolean — campus environment
    "is_urban",                   # Boolean — urban core
    "poi_density",                # Nearby POI count / 50
    
    # ── Dynamic Features ──
    "live_events_norm",           # Active Ticketmaster events / 30
    "live_incidents_norm",        # Active Socrata/Citizen incidents / 50
    "moon_illumination",          # 0-1 luminosity factor
    
    # ── Derived Features ──
    "spatial_density_score",      # Output of M2 (spatial estimator)
]
```

### 9.4 Training Data Construction

```python
def build_training_dataset():
    """
    Build XGBoost training set from ALL NIBRS data.
    
    For each agency with sufficient data:
      - Compute real crime rates (ground truth)
      - Compute temporal profiles
      - Generate training examples across time variations
      - Label with NIBRS-derived safety scores (NOT formula-derived)
    
    Expected: ~100K–500K training examples from 15K+ agencies
    """
    agencies = load_all_agencies()  # ~15K agencies across all states
    training_data = []
    
    for agency in agencies:
        if agency.total_incidents < 50:  # skip agencies with very sparse data
            continue
            
        # Ground truth: real Part I crime rate from NIBRS
        real_rate = agency.annual_part1_rate
        
        # Temporal profiles: real distributions from NIBRS
        hourly_dist = agency.hourly_distribution  # 24-element array
        dow_dist = agency.dow_distribution  # 7-element array
        monthly_dist = agency.monthly_distribution  # 12-element array
        
        # Generate examples across temporal variations
        for hour in range(24):
            for dow in range(7):
                for gender in ["female", "male", "mixed"]:
                    for group_size in [1, 2, 3, 4]:
                        features = build_feature_vector(
                            agency, hour, dow, gender, group_size,
                            weather=random_weather(),
                            events=random_events(agency.is_urban),
                        )
                        
                        # GROUND TRUTH LABEL — from real NIBRS data, NOT formula
                        label = compute_nibrs_safety_label(
                            real_rate, 
                            hourly_dist[hour],
                            dow_dist[dow],
                            agency.weapon_rate,
                            agency.stranger_rate,
                            agency.officer_density,
                            gender,
                            group_size,
                        )
                        
                        training_data.append((features, label))
    
    return training_data
```

### 9.5 Model Configuration

```python
import xgboost as xgb

params = {
    "objective": "reg:squarederror",
    "eval_metric": ["rmse", "mae"],
    "max_depth": 8,
    "learning_rate": 0.05,
    "n_estimators": 500,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "reg_alpha": 0.1,
    "reg_lambda": 1.0,
    "min_child_weight": 5,
    "gamma": 0.1,
    "tree_method": "hist",  # Fast histogram-based
    "random_state": 42,
}

model = xgb.XGBRegressor(**params)
model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    early_stopping_rounds=20,
    verbose=True,
)
```

### 9.6 Inference Integration

```python
# In scoring.py — replaces the current compute_safety_score()

def compute_safety_score_v2(features_dict, xgb_model, 
                             temporal_profiles, spatial_estimator):
    """
    New scoring pipeline:
    1. Temporal risk from M1 (lookup table)
    2. Spatial density from M2 (agency matching)
    3. Final score from M3 (XGBoost)
    4. Gemini refinement (±15, unchanged)
    """
    # M1: Temporal risk ratio for this state + hour
    hourly_risk = temporal_profiles[state_abbr][hour]
    mean_risk = temporal_profiles[state_abbr].mean()
    hourly_risk_ratio = hourly_risk / mean_risk if mean_risk > 0 else 1.0
    
    # M2: Spatial crime density from agency matching
    spatial_density = spatial_estimator.estimate(
        city_name, state_abbr, population, lat, lng
    )
    
    # M3: XGBoost final prediction
    feature_vector = build_inference_features(
        spatial_density, hourly_risk_ratio, 
        weather, gender, people_count, ...
    )
    safety_score = int(xgb_model.predict(feature_vector) * 100)
    safety_score = max(5, min(95, safety_score))
    
    return safety_score
```

---

## 10. Ensemble Integration & Scoring Pipeline

### 10.1 New Pipeline Flow

```
Request comes in (lat, lng, hour, gender, people_count, ...)
    │
    ├──→ [1] Identify agency: fuzzy match city_name → NIBRS agency
    │         → Get agency's real Part I crime rate
    │         → Get agency's offense mix, weapon rate, victim demographics
    │
    ├──→ [2] M1: Look up temporal risk
    │         → state_abbr → hourly_distribution[hour]
    │         → state_abbr → dow_distribution[day_of_week]
    │         → state_abbr → monthly_distribution[month]
    │
    ├──→ [3] M2: Compute spatial density
    │         → agency match → real rate
    │         → OR county → median
    │         → OR state + pop_group → median
    │
    ├──→ [4] Fetch contextual data (parallel, unchanged)
    │         → weather, POIs, events, incidents, moon
    │
    ├──→ [5] M3: XGBoost prediction
    │         → Build 25-feature vector
    │         → Predict safety_score (0-1)
    │         → Scale to (0-100)
    │
    ├──→ [6] Gemini refinement (unchanged)
    │         → ±15 contextual adjustment
    │
    └──→ [7] Return SafetyResponse
```

### 10.2 Scoring Weight Distribution (New vs Old)

| Component | Current Weight | New Weight |
|-----------|---------------|------------|
| Formula (heuristic) | 85% | 0% (eliminated) |
| Dense NN (circular) | 15% | 0% (eliminated) |
| M1: Temporal profiles | 0% | Baked into M3 features |
| M2: Spatial density | 0% | Baked into M3 features |
| M3: XGBoost scorer | 0% | **100% of base score** |
| Gemini refinement | ±15 points | ±15 points (unchanged) |

### 10.3 Fallback Chain

```
IF XGBoost model available AND NIBRS profiles loaded:
    → Use full ensemble pipeline (M1 + M2 + M3)
    
ELIF NIBRS profiles loaded but no XGBoost:
    → Use formula + NIBRS temporal profiles (hybrid fallback)
    
ELIF nothing loaded:
    → Use current formula-only pipeline (backward compatible)
```

---

## 11. Feature Engineering from NIBRS

### 11.1 Per-Agency Features (Pre-computed at Startup/Build Time)

```python
class AgencyProfile:
    """Pre-computed profile for each NIBRS agency."""
    
    # Identity
    agency_id: str
    agency_name: str
    state_abbr: str
    county: str
    population: int
    population_group: int  # FBI classification (1-11)
    agency_type: str  # City, County Sheriff, University, State
    
    # Crime Rates (per 100K, annualized)
    part1_rate: float           # Part I Index Crimes
    violent_rate: float         # Violent Part I
    property_rate: float        # Property Part I
    total_rate: float           # All offenses
    
    # Offense Mix (fractions summing to 1)
    offense_mix: dict[str, float]  # offense_code → fraction
    
    # Temporal Distributions (from incident timestamps)
    hourly_dist: np.ndarray     # (24,) normalized
    dow_dist: np.ndarray        # (7,) normalized  
    monthly_dist: np.ndarray    # (12,) normalized
    
    # Severity Metrics
    severity_weighted_rate: float  # rate × mean_severity
    weapon_rate: float             # fraction of offenses with weapons
    stranger_rate: float           # fraction of crimes by strangers
    
    # Victim Demographics
    victim_female_rate: float      # fraction of victims who are female
    victim_male_rate: float
    mean_victim_age: float
    
    # Officer Density
    officers_per_1000: float
    
    # Data Quality
    n_years: int                   # how many years of data
    total_incidents: int           # total incidents across all years
    latest_year: int               # most recent data year
```

### 11.2 Inference-Time Features (Computed Per Request)

```python
def build_inference_features(agency_profile, hour, day_of_week, month,
                              gender, people_count, weather_severity,
                              poi_density, live_events, live_incidents,
                              moon_illumination, is_college):
    """Build the 25-feature vector for XGBoost inference."""
    
    ap = agency_profile
    
    # Temporal risk ratios (relative to mean)
    mean_hourly = ap.hourly_dist.mean()
    hourly_risk_ratio = ap.hourly_dist[hour] / mean_hourly if mean_hourly > 0 else 1.0
    
    mean_dow = ap.dow_dist.mean()
    dow_risk_ratio = ap.dow_dist[day_of_week] / mean_dow if mean_dow > 0 else 1.0
    
    mean_monthly = ap.monthly_dist.mean()
    monthly_risk_ratio = ap.monthly_dist[month] / mean_monthly if mean_monthly > 0 else 1.0
    
    # Gender risk from NIBRS victim demographics
    if gender == "female":
        gender_factor = ap.victim_female_rate
    elif gender == "male":
        gender_factor = ap.victim_male_rate
    else:
        gender_factor = 0.5
    
    return np.array([
        min(ap.part1_rate / 8000, 1.0),        # agency_part1_rate
        min(ap.violent_rate / 2000, 1.0),       # agency_violent_rate
        min(ap.property_rate / 6000, 1.0),      # agency_property_rate
        ap.weapon_rate,                          # agency_weapon_rate
        ap.stranger_rate,                        # agency_stranger_rate
        min(ap.severity_weighted_rate / 50000, 1.0),  # agency_severity_score
        min(state_rate / 8000, 1.0),            # state_crime_rate_norm
        ap.population_group / 11.0,             # population_group
        hourly_risk_ratio,                       # hourly_risk_ratio
        dow_risk_ratio,                          # dow_risk_ratio
        monthly_risk_ratio,                      # monthly_risk_ratio
        math.sin(2 * math.pi * hour / 24),      # time_sin
        math.cos(2 * math.pi * hour / 24),      # time_cos
        float(day_of_week >= 5),                 # is_weekend
        min(people_count / 4, 1.0),             # people_count_norm
        gender_factor,                           # gender_factor
        weather_severity,                        # weather_severity
        min(ap.officers_per_1000 / 5, 1.0),     # officer_density
        is_college,                              # is_college
        float(ap.population > 250_000),          # is_urban
        poi_density,                             # poi_density
        min(live_events / 30, 1.0),             # live_events_norm
        min(live_incidents / 50, 1.0),          # live_incidents_norm
        moon_illumination,                       # moon_illumination
        min(ap.part1_rate / 5000, 1.0),         # spatial_density_score (normalize)
    ], dtype=np.float32)
```

---

## 12. Data Preprocessing Pipeline

### 12.1 Overview

The preprocessing pipeline runs **once** (at build time, not at server startup) and produces pre-computed artifacts:

```
58M raw NIBRS CSVs → Preprocessing Pipeline → Artifacts
                                                  ├── agency_profiles.json (~15K agencies)
                                                  ├── state_temporal_profiles.json (51 states)
                                                  ├── xgboost_model.ubj (~5MB)
                                                  └── training_metadata.json
```

### 12.2 Steps

```python
# Step 1: Load all agencies across all state-year directories
#   - Deduplicate by agency_id (keep highest population / latest year)
#   - ~15K unique agencies expected

# Step 2: For each agency, count incidents per hour, day, month
#   - Load NIBRS_incident.csv from each state-year dir
#   - Group by agency_id
#   - Compute hourly_dist, dow_dist, monthly_dist

# Step 3: For each agency, compute offense statistics
#   - Join NIBRS_incident → NIBRS_OFFENSE on incident_id
#   - Classify offenses as Part I / Part II
#   - Compute offense mix, severity scores

# Step 4: Compute weapon rates per agency
#   - Join NIBRS_OFFENSE → NIBRS_WEAPON on offense_id
#   - Compute fraction of offenses with weapons

# Step 5: Compute victim demographics per agency
#   - Load NIBRS_VICTIM.csv
#   - Group by agency (via incident_id)
#   - Compute female/male victim rates, mean age

# Step 6: Compute stranger crime rates per agency
#   - Load NIBRS_VICTIM_OFFENDER_REL.csv
#   - Join with relationship lookup
#   - Compute fraction stranger/unknown

# Step 7: Aggregate into state-level temporal profiles
#   - Merge all agencies in each state
#   - Produce state_hourly_dist, state_dow_dist, state_monthly_dist

# Step 8: Build training dataset for XGBoost
#   - For each agency with sufficient data (>50 incidents)
#   - Generate training examples across temporal/contextual variations
#   - Label with NIBRS-derived ground truth (empirical safety scores)

# Step 9: Train XGBoost model
#   - 80/10/10 split (stratified by state)
#   - Train with early stopping
#   - Save model and metadata
```

### 12.3 Memory Management

With 58M incidents, we **cannot** load everything into memory. Two approaches:

#### Approach A: Stream Processing (Recommended)
```python
def process_state_year(state_abbr, year):
    """Process one state-year directory at a time."""
    incident_path = datasets_dir / f"{state_abbr}-{year}" / "NIBRS_incident.csv"
    
    # Streaming counters — never hold all rows in memory
    hourly_counts = defaultdict(lambda: np.zeros(24))  # agency_id → hourly
    dow_counts = defaultdict(lambda: np.zeros(7))
    monthly_counts = defaultdict(lambda: np.zeros(12))
    agency_incident_counts = defaultdict(int)
    
    with open(incident_path, encoding="utf-8", errors="replace") as f:
        reader = csv.DictReader(f)
        for row in reader:
            aid = row.get("agency_id") or row.get("AGENCY_ID", "")
            hour = safe_int(row.get("incident_hour") or row.get("INCIDENT_HOUR"), -1)
            date_str = row.get("incident_date") or row.get("INCIDENT_DATE", "")
            
            if aid and 0 <= hour <= 23:
                hourly_counts[aid][hour] += 1
                agency_incident_counts[aid] += 1
                
            # Parse date for dow and month
            if date_str:
                try:
                    dt = parse_date(date_str)
                    dow_counts[aid][dt.weekday()] += 1
                    monthly_counts[aid][dt.month - 1] += 1
                except: pass
    
    return hourly_counts, dow_counts, monthly_counts, agency_incident_counts
```

#### Approach B: Chunked pandas (Alternative)
```python
import pandas as pd

def process_chunked(filepath, chunksize=100_000):
    """Process large CSVs in chunks to limit memory."""
    for chunk in pd.read_csv(filepath, chunksize=chunksize, 
                              low_memory=False, encoding_errors="replace"):
        # Process each chunk
        hourly = chunk.groupby(["agency_id", "incident_hour"]).size()
        yield hourly
```

### 12.4 Schema Normalization

Handle the three CSV format generations:

```python
def normalize_row(row: dict) -> dict:
    """Normalize NIBRS CSV row to standard format regardless of year."""
    # Uppercase all keys (handles 2018-2019 quoted uppercase + 2022+ lowercase)
    norm = {k.upper(): v for k, v in row.items()}
    
    # Handle legacy format (pre-2006): no DATA_YEAR column
    if "DATA_YEAR" not in norm:
        # Infer from directory name
        norm["DATA_YEAR"] = inferred_year
    
    return norm
```

---

## 13. NIBRS Data Integration — Expanding nibrs_data.py

### 13.1 Current State

`nibrs_data.py` currently:
- Loads ONLY from `GA-2018` through `GA-2024` directories 
- Builds a single `NIBRSStatistics` singleton
- Provides `get_state_crime_profile()` which returns real NIBRS data for GA and BJS-derived synthetic data for all other states

### 13.2 Required Changes

```python
# nibrs_data.py — EXPANSION PLAN

class AllStateNIBRSStatistics:
    """
    Expanded NIBRS pipeline loading data from ALL 51 states.
    
    Replaces the GA-only NIBRSStatistics singleton.
    """
    
    def __init__(self):
        # Per-state temporal profiles
        self.state_hourly: dict[str, np.ndarray] = {}   # state → (24,)
        self.state_dow: dict[str, np.ndarray] = {}      # state → (7,)
        self.state_monthly: dict[str, np.ndarray] = {}  # state → (12,)
        
        # Per-state aggregates
        self.state_weapon_rate: dict[str, float] = {}
        self.state_stranger_rate: dict[str, float] = {}
        self.state_victim_gender: dict[str, dict] = {}
        self.state_offense_mix: dict[str, dict] = {}
        self.state_severity_dist: dict[str, np.ndarray] = {}
        
        # Per-agency profiles (the core of M2)
        self.agency_profiles: dict[str, AgencyProfile] = {}  # agency_name_lower → profile
        
        # National aggregates
        self.national_hourly: np.ndarray = np.ones(24) / 24
        self.national_weapon_rate: float = 0.0
        
    def load_all(self):
        """
        Load NIBRS data from ALL state-year directories.
        
        Processing order:
        1. Scan datasets/ for all ??-???? directories
        2. Load agencies.csv from each (deduplicate)
        3. Stream NIBRS_incident.csv for hourly/dow/monthly counts
        4. Stream NIBRS_OFFENSE.csv for offense mix and location risk
        5. Stream NIBRS_WEAPON.csv for weapon rates
        6. Stream NIBRS_VICTIM.csv for demographics
        7. Aggregate into state-level and agency-level profiles
        """
        ...
    
    def get_agency_profile(self, city_name, state_abbr) -> AgencyProfile:
        """Look up agency profile for any US city."""
        ...
    
    def get_hourly_risk_curve(self, state_abbr, base_risk) -> np.ndarray:
        """
        Real data-driven hourly risk curve for ANY state.
        No more BJS synthetic fallback!
        """
        ...
```

### 13.3 Loading Strategy: Pre-computed vs Runtime

**Option A: Pre-compute offline, load JSON at startup (Recommended)**
```
python precompute_nibrs.py  →  agency_profiles.json + state_profiles.json
                              (run once, takes 10-30 min)

Server startup: Load JSON files (~5-20MB) into memory
                (takes 1-5 seconds)
```

**Option B: Load raw CSVs at server startup**
```
Server startup: Stream 48GB of CSVs  →  Takes 30+ minutes
                NOT viable for development iteration
```

**Verdict:** Option A is the only practical path. Build a `precompute_nibrs.py` script.

---

## 14. Training Infrastructure

### 14.1 Training Script (`train_safety_model.py`)

```python
"""
Lumos ML Training Pipeline v2

Usage:
    python train_safety_model.py [--rebuild-profiles] [--model xgboost|lightgbm]

Steps:
    1. Load pre-computed agency profiles (from precompute_nibrs.py)
    2. Generate training examples with NIBRS-derived labels
    3. Train gradient-boosted tree model
    4. Evaluate on held-out test set
    5. Save model + metadata
"""

def main():
    # Load pre-computed profiles
    profiles = load_agency_profiles()  # ~15K agencies
    
    # Build training dataset
    X_train, y_train, X_val, y_val, X_test, y_test = build_training_splits(profiles)
    
    # Train
    model = train_xgboost(X_train, y_train, X_val, y_val)
    
    # Evaluate
    evaluate(model, X_test, y_test)
    
    # Feature importance
    show_feature_importance(model)
    
    # Save
    model.save_model("safety_model.ubj")
```

### 14.2 Dependencies

**Remove:** `tensorflow` (~500MB)  
**Add:** `xgboost` (~7MB) or `lightgbm` (~3MB)

```
# Updated requirements.txt changes
- tensorflow>=2.15
+ xgboost>=2.0
+ lightgbm>=4.0  # optional, as alternative to xgboost
```

### 14.3 Model Artifacts

| Artifact | Size | Description |
|----------|------|-------------|
| `safety_model.ubj` | ~5MB | XGBoost model (Universal Binary JSON) |
| `agency_profiles.json` | ~10-20MB | Pre-computed agency profiles |
| `state_temporal_profiles.json` | ~50KB | 51 states × (24 + 7 + 12) temporal arrays |
| `training_metadata.json` | ~2KB | Training metrics, feature names, data version |

---

## 15. Evaluation & Validation Strategy

### 15.1 Metrics

| Metric | Description | Target |
|--------|------------|--------|
| **MAE** | Mean Absolute Error on safety score (0-100) | < 5 points |
| **RMSE** | Root Mean Squared Error | < 8 points |
| **Rank Correlation (Spearman)** | Does the model rank locations correctly? | > 0.90 |
| **Accuracy@10** | % of predictions within ±10 points of ground truth | > 80% |
| **Cross-State Generalization** | Performance on held-out states | Within 20% of in-state perf |

### 15.2 Validation Strategies

#### A. Temporal Holdout
- Train on 2006–2022 data
- Validate on 2023 data
- Test on 2024 data
- Tests: "Can the model predict future crime patterns?"

#### B. Geographic Holdout
- Hold out 5 states entirely from training
- Test generalization to unseen geographies
- Tests: "Can the model generalize to new states?"

#### C. Agency Holdout
- Within each state, hold out 20% of agencies
- Tests: "Can the model estimate crime for agencies it hasn't seen?"

#### D. Reality Check Benchmarks
```
Known safe cities should score > 70:
  - Irvine, CA (one of America's safest cities)
  - Naperville, IL
  - Frisco, TX

Known dangerous cities should score < 35:
  - St. Louis, MO (highest violent crime rate)
  - Detroit, MI
  - Baltimore, MD

Time sensitivity checks:
  - Same location at 2 PM should score > same location at 2 AM
  
Group size checks:
  - Group of 4 should score > solo traveler at same location
```

### 15.3 A/B Testing (Production)

After deployment, log both old formula scores and new ML scores. Compare:
- Do they diverge significantly?
- Does the ML model produce more nuanced temporal differentiation?
- Do users find the new scores more accurate? (implicit via engagement metrics)

---

## 16. Migration Plan — Phased Implementation

### Phase 1: Data Preprocessing (Estimated: 3-4 hours)

**Goal:** Build the preprocessing pipeline and generate artifacts.

| Task | Time | Output |
|------|------|--------|
| Write `precompute_nibrs.py` script | 2 hr | Script that streams all NIBRS CSVs |
| Run preprocessing on all 51 states | 30 min | `agency_profiles.json`, `state_temporal_profiles.json` |
| Validate output (spot-check known cities) | 30 min | Verified profiles |
| Handle schema variations (pre-2006 vs 2020+) | 30 min | Unified normalization |

### Phase 2: Temporal Risk Model — M1 (Estimated: 1-2 hours)

**Goal:** Replace BJS synthetic curves with pre-computed real profiles.

| Task | Time | Output |
|------|------|--------|
| Update `nibrs_data.py` to load state_temporal_profiles.json | 30 min | `AllStateNIBRSStatistics` |
| Update `get_hourly_risk_curve()` to use real state data | 30 min | Real 24-hour curves |
| Update `get_state_crime_profile()` to use real data for all states | 30 min | No more BJS fallback |
| Test hourly risk charts for multiple states | 30 min | Verified charts |

### Phase 3: Spatial Density Model — M2 (Estimated: 1-2 hours)

**Goal:** Replace state × multiplier heuristic with agency-level matching.

| Task | Time | Output |
|------|------|--------|
| Build `SpatialDensityEstimator` class | 1 hr | Multi-tier agency matching |
| Update `estimate_local_crime_rate()` to use M2 | 30 min | Real per-city rates |
| Extend fuzzy matching to all 15K agencies (not just GA) | 30 min | Nationwide agency lookup |

### Phase 4: Contextual Scorer Model — M3 (Estimated: 2-3 hours)

**Goal:** Train and integrate XGBoost model with NIBRS-derived labels.

| Task | Time | Output |
|------|------|--------|
| Write `train_safety_model.py` | 1 hr | Training script |
| Implement NIBRS-derived label generation | 30 min | Ground truth labels |
| Train XGBoost model | 30 min | `safety_model.ubj` |
| Update `scoring.py` to use XGBoost instead of Keras NN | 30 min | New inference pipeline |
| Update `ml_model.py` to load XGBoost model | 30 min | Lazy loader update |

### Phase 5: Integration & Testing (Estimated: 1-2 hours)

**Goal:** Wire everything together and validate.

| Task | Time | Output |
|------|------|--------|
| Update `routes.py` to use new scoring pipeline | 30 min | New endpoints |
| Remove TensorFlow dependency | 15 min | Lighter requirements |
| End-to-end testing with known cities | 30 min | Validated scores |
| Performance benchmarking | 15 min | Inference latency data |
| Update `compute_safety_score()` signature | 15 min | Clean API |

### Total Estimated Time: 8-13 hours

---

## 17. Risk Assessment & Mitigations

### 17.1 Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Preprocessing takes too long (48GB) | Medium | Delays Phase 1 | Stream + parallelize; process recent years first |
| Memory issues during preprocessing | Medium | Crash | Use streaming CSV reader, never load full file |
| XGBoost overfitting on agency profiles | Low | Bad generalization | Use geographic holdout, early stopping |
| Agency fuzzy matching accuracy | Medium | Wrong crime rates | Multi-tier fallback (exact → county → pop_group → state) |
| NIBRS agency names don't match Google geocoding | Medium | Can't match user location to agency | Build mapping table: Google city name → closest NIBRS agency |
| Pre-2006 CSV format breaks parser | Low | Missing older data | Skip pre-2006 for now; focus on 2006+ |
| Model produces extreme scores (0 or 100) | Low | Bad UX | Clamp to [5, 95]; add Gemini as sanity check |

### 17.2 Data Quality Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Some agencies have very sparse data (<50 incidents) | High | Unreliable rates | Filter out; fall back to county/state median |
| Population data is stale (older years) | Medium | Rate miscalculation | Use latest available year's population |
| NIBRS coverage varies by state/year | High | Inconsistent quality | Weight training examples by data quality |
| Empty directories (225 of 774) | Known | Missing data | Handled: only process dirs with NIBRS_incident.csv |
| Duplicate incidents from nested directories | Known | Double-counting | Deduplicate by (data_year, incident_id) |

### 17.3 Hackathon-Specific Risks

| Risk | Mitigation |
|------|------------|
| Not enough time for full implementation | Phase 1+2 alone is a huge improvement over current state |
| Competition uses TensorFlow/Keras | XGBoost is a recognized ML framework; NIBRS data is the real flex |
| Judges want to see neural networks | Keep XGBoost for scoring, add LSTM for temporal if time allows |
| Demo breaks during presentation | Pre-compute results for demo cities; cache heavily |

---

## Appendix A: NIBRS Schema Reference

### Core Tables

| Table | Primary Key | Foreign Keys | Record Count (per state-year) |
|-------|------------|--------------|------------------------------|
| `NIBRS_incident` | incident_id | agency_id (→ agencies) | 15K–1.5M |
| `NIBRS_OFFENSE` | offense_id | incident_id, offense_code, location_id | 20K–2M |
| `NIBRS_VICTIM` | victim_id | incident_id, age_id, sex_code, race_id | 15K–1.5M |
| `NIBRS_OFFENDER` | offender_id | incident_id | 10K–1M |
| `NIBRS_ARRESTEE` | arrestee_id | incident_id | 5K–500K |
| `NIBRS_WEAPON` | weapon_id | offense_id | 5K–500K |
| `NIBRS_PROPERTY` | property_id | incident_id | 10K–1M |
| `agencies` | agency_id | — | 50–3000 |

### Key Column Reference

**NIBRS_incident.csv:**
```
data_year | agency_id | incident_id | nibrs_month_id | cargo_theft_flag
submission_date | incident_date | report_date_flag | incident_hour
cleared_except_id | cleared_except_date | incident_status
data_home | orig_format | did
```

**NIBRS_OFFENSE.csv:**
```
data_year | offense_id | incident_id | offense_code | attempt_complete_flag
location_id | num_premises_entered | method_entry_code
```

**agencies.csv (modern format):**
```
yearly_agency_id | agency_id | data_year | ori | legacy_ori
pub_agency_name | state_abbr | state_postal_abbr
agency_type_name | population | county_name
population_group_code | population_group_desc
male_officer | female_officer | officer_rate | employee_rate
nibrs_cert_date | participated | nibrs_participated
```

### Location Types (46 categories)

```
01: Air/Bus/Train Terminal          25: Parking/Drop Lot/Garage
02: Bank/Savings and Loan           26: Rental Storage Facility
03: Bar/Nightclub                   27: Residence/Home
04: Church/Synagogue/Temple         28: Rest Area
05: Commercial/Office Building      29: School - College/University
06: Construction Site               30: School - Elementary/Secondary
07: Convenience Store               31: Shelter - Mission/Homeless
08: Department/Discount Store       32: Service/Gas Station
09: Drug Store/Doctor/Hospital      33: Specialty Store
10: Field/Woods                     34: Other/Unknown
11: Government/Public Building      35: Tribal Lands
12: Grocery/Supermarket             36: Community Center
13: Highway/Road/Alley/Street/Sidewalk
14: Hotel/Motel/Etc.
15: Industrial Site
16: Jail/Prison/Penitentiary/Camp
17: Lake/Waterway/Beach
18: Liquor Store
19: Parking/Drop Lot/Garage
20: Cyberspace
... (46 total)
```

---

## Appendix B: State Data Coverage Matrix

| State | First Year | Latest Year | Total Years | 2024? | Est. Total Incidents |
|-------|-----------|-------------|-------------|-------|---------------------|
| AL | 1991 | 2024 | 25 | ✅ | ~3.5M |
| AK | 2021 | 2024 | 4 | ✅ | ~60K |
| AZ | 2006 | 2023 | 19 | ❌ | ~3M |
| AR | 2006 | 2024 | 19 | ✅ | ~2.5M |
| CA | 2021 | 2024 | 4 | Empty? | ~1M+ |
| CO | 1992 | 2024 | 21 | ✅ | ~4.5M |
| CT | 2006 | 2024 | 19 | ✅ | ~1.8M |
| DC | 2001 | 2024 | 24 | ✅ | ~1.5M |
| DE | 2006 | 2024 | 19 | ✅ | ~900K |
| FL | 2021 | 2024 | 4 | ✅ | ~1M |
| GA | 2018 | 2024 | 7 | ✅ | ~2.5M |
| HI | 2019 | 2023 | 5 | ❌ | ~150K |
| IA | 2000 | 2024 | 20 | ✅ | ~1.8M |
| ID | 2000 | 2024 | 20 | ✅ | ~800K |
| IL | 2006 | 2024 | 16 | ✅ | ~5M |
| IN | 2014 | 2024 | 8 | ✅ | ~1.2M |
| KS | 2000 | 2024 | 21 | ✅ | ~2M |
| KY | 2000 | 2024 | 21 | ✅ | ~2.5M |
| LA | 2003 | 2024 | 17 | ✅ | ~2M |
| MA | 2001 | 2023 | 19 | ❌ | ~1.5M |
| MD | 2018 | 2024 | 6 | ✅ | ~1.3M |
| ME | 2004 | 2024 | 18 | ✅ | ~600K |
| MI | 2001 | 2024 | 20 | ✅ | ~5M |
| MN | 2018 | 2024 | 6 | ✅ | ~1M |
| MO | 2006 | 2024 | 16 | ✅ | ~3M |
| MS | 2018 | 2024 | 6 | ✅ | ~300K |
| MT | 2005 | 2024 | 17 | ✅ | ~500K |
| NC | 2019 | 2024 | 5 | ✅ | ~2M |
| ND | 2000 | 2024 | 21 | ✅ | ~500K |
| NE | 2001 | 2023 | 19 | ❌ | ~600K |
| NH | 2002 | 2024 | 20 | ✅ | ~600K |
| NJ | 2021 | 2023 | 3 | ❌ | ~500K |
| NM | 2018 | 2024 | 6 | ✅ | ~500K |
| NV | 2020 | 2024 | 5 | ✅ | ~700K |
| NY | 2020 | 2024 | 4 | ✅ | ~2.5M |
| OH | 2000 | 2024 | 22 | ✅ | ~6M |
| OK | 2008 | 2023 | 14 | ❌ | ~1.5M |
| OR | 2003 | 2024 | 18 | ✅ | ~2.5M |
| PA | 2012 | 2024 | 11 | ✅ | ~2.5M |
| RI | 2005 | 2024 | 17 | ✅ | ~500K |
| SC | 2000 | 2024 | 21 | ✅ | ~3.5M |
| SD | 2000 | 2024 | 21 | ✅ | ~500K |
| TN | 2000 | 2024 | 18 | ✅ | ~4M |
| TX | 2000 | 2024 | 21 | ✅ | **~15M** |
| UT | 2000 | 2024 | 21 | ✅ | ~2M |
| VA | 2001 | 2023 | 20 | ❌ | ~4M |
| VT | 2000 | 2024 | 21 | ✅ | ~300K |
| WA | 2005 | 2024 | 18 | ✅ | ~4M |
| WI | 2005 | 2024 | 17 | ✅ | ~2.5M |
| WV | 2000 | 2024 | 21 | ✅ | ~800K |
| WY | 2020 | 2024 | 5 | ✅ | ~80K |

**Total: ~58M incident records across 546 state-year directories with data**

---

## Appendix C: Discarded Architecture Options

### C.1 Convolutional Neural Networks (CNN)
- **Why considered:** Could process spatial grid data
- **Why discarded:** NIBRS doesn't have lat/lng per incident — only agency-level granularity. No spatial grid to convolve over.

### C.2 Variational Autoencoders (VAE)
- **Why considered:** Could learn latent safety representations
- **Why discarded:** Unsupervised — doesn't help with the core problem of needing safety scores. Generative models are overkill.

### C.3 Reinforcement Learning
- **Why considered:** Could learn optimal safety recommendations
- **Why discarded:** No reward signal. Safety scoring isn't a sequential decision problem. Entirely wrong paradigm.

### C.4 Full Spatial-Temporal GNN (ST-GCN)
- **Why considered:** State-of-the-art for traffic/crime forecasting in academic literature
- **Why discarded for hackathon:** 
  1. Requires agency adjacency graph (needs geocoding or FIPS code joining)
  2. PyTorch Geometric dependency adds complexity
  3. Training on sparse agency graph is fragile
  4. Marginal benefit over XGBoost for this specific use case
  5. Implementation time: 8-15 hours (too much for hackathon)
- **Future potential:** Post-hackathon, if Census FIPS codes are added to map agencies to geographic coordinates, an ST-GCN could model spatial crime diffusion between neighboring jurisdictions — this is where GNNs genuinely shine.

### C.5 Gaussian Process Regression
- **Why considered:** Naturally handles uncertainty, good for spatial interpolation
- **Why discarded:** O(n³) scaling with number of training points makes it infeasible for 15K+ agencies. Would need sparse GP approximations, adding complexity.

### C.6 Large Language Model Fine-tuning
- **Why considered:** Could learn from crime description text
- **Why discarded:** NIBRS data is structured (codes, counts), not free text. LLM fine-tuning would be an absurd overhead. Gemini already handles the text/context piece.

---

## Summary of Key Decisions

| Decision | Choice | Rationale |
|----------|--------|-----------|
| **Architecture** | Multi-model ensemble (M1 + M2 + M3) | Specialization beats one-model-fits-all |
| **M1 (Temporal)** | Pre-computed lookup tables | Empirical distributions are perfect data, no modeling needed |
| **M2 (Spatial)** | Statistical agency matching + KDE | NIBRS gives us 15K agency crime rates — just look them up |
| **M3 (Contextual)** | XGBoost gradient-boosted trees | State-of-the-art for tabular data, 100× lighter than TF |
| **Ground truth** | NIBRS-derived empirical rates | Breaks circular training dependency |
| **Preprocessing** | Offline pre-computation → JSON artifacts | 48GB cannot be loaded at server startup |
| **TensorFlow** | Remove | XGBoost is lighter, faster, and better for tabular data |
| **Gemini** | Keep as-is | Subjective contextual refinement complements ML models |
| **Spatial GNN** | Defer to post-hackathon | Too complex for hackathon; agency matching achieves 90% of benefit |
| **LSTM temporal** | Defer (use lookup tables) | Pre-computed empirical distributions are better than learned approximations |

---

*Generated for Hacklytics 2026 — February 21, 2026*
*Based on audit of 774 state-year NIBRS directories, ~58M incident records, 48GB of data*
